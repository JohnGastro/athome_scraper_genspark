#!/usr/bin/env python
"""
Athome Property Scraper å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import sys
import os
import logging
from datetime import datetime
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

from config.athome_scraper_config import *
from src.selenium_scraper import SeleniumAthomeScraper
from src.database import PropertyDatabase


def setup_logging():
    """ãƒ­ã‚®ãƒ³ã‚°ã‚’è¨­å®š"""
    log_dir = LOG_CONFIG['log_dir']
    log_dir.mkdir(parents=True, exist_ok=True)
    
    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ—¥ä»˜ä»˜ãï¼‰
    log_file = log_dir / f"scraper_{datetime.now().strftime('%Y%m%d')}.log"
    
    # ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
    logging.basicConfig(
        level=getattr(logging, LOG_CONFIG['log_level']),
        format=LOG_CONFIG['log_format'],
        datefmt=LOG_CONFIG['log_date_format'],
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
    # å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’èª¿æ•´
    logging.getLogger('urllib3').setLevel(logging.WARNING)
    logging.getLogger('requests').setLevel(logging.WARNING)
    
    return logging.getLogger(__name__)


def run_scraping():
    """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’å®Ÿè¡Œ"""
    logger = setup_logging()
    logger.info("="*60)
    logger.info("Athome Property Scraper èµ·å‹•")
    logger.info("="*60)
    
    try:
        # è¨­å®šã‚’è¾æ›¸åŒ–
        config = {
            'ATHOME_BASE_URL': ATHOME_BASE_URL,
            'ATHOME_SEARCH_URL': ATHOME_SEARCH_URL,
            'SCRAPING_CONFIG': SCRAPING_CONFIG,
            'DATABASE_CONFIG': DATABASE_CONFIG,
            'RANK_THRESHOLDS': RANK_THRESHOLDS,
            'RANKING_WEIGHTS': RANKING_WEIGHTS,
            'PRICE_CRITERIA': PRICE_CRITERIA,
            'PREMIUM_AREAS': PREMIUM_AREAS,
            'STATION_DISTANCE_CRITERIA': STATION_DISTANCE_CRITERIA,
            'AREA_CRITERIA': AREA_CRITERIA,
            'INVESTMENT_CRITERIA': INVESTMENT_CRITERIA,
        }
        
        # Seleniumã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚’å®Ÿè¡Œ
        scraper = SeleniumAthomeScraper(config)
        stats = scraper.scrape_all()
        
        # çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        logger.info("\n" + "="*60)
        logger.info("å®Ÿè¡Œçµæœã‚µãƒãƒªãƒ¼")
        logger.info("="*60)
        logger.info(f"ç·å‡¦ç†ä»¶æ•°: {stats['total_properties']}ä»¶")
        logger.info(f"æ–°è¦ç‰©ä»¶: {stats['new_properties']}ä»¶")
        logger.info(f"æ›´æ–°ç‰©ä»¶: {stats['updated_properties']}ä»¶")
        logger.info(f"ã‚¨ãƒ©ãƒ¼: {stats['errors']}ä»¶")
        
        if stats['start_time'] and stats['end_time']:
            duration = (stats['end_time'] - stats['start_time']).total_seconds()
            logger.info(f"å®Ÿè¡Œæ™‚é–“: {duration:.1f}ç§’")
        
        # é«˜ãƒ©ãƒ³ã‚¯ç‰©ä»¶ã‚’è¡¨ç¤º
        db = PropertyDatabase(DATABASE_CONFIG['db_path'])
        high_rank_properties = db.get_active_properties(['S', 'A'])
        
        if high_rank_properties:
            logger.info("\n" + "="*60)
            logger.info("ğŸ† é«˜ãƒ©ãƒ³ã‚¯ç‰©ä»¶ï¼ˆS/Aç´šï¼‰")
            logger.info("="*60)
            
            for prop in high_rank_properties[:5]:  # ä¸Šä½5ä»¶
                logger.info(
                    f"{prop['ranking_grade']}ç´š ({prop['ranking_score']:.1f}ç‚¹) - "
                    f"{prop['title']} - {prop['price']} - {prop['address']}"
                )
        
        # CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        if OUTPUT_CONFIG.get('export_formats') and 'csv' in OUTPUT_CONFIG['export_formats']:
            export_dir = OUTPUT_CONFIG.get('export_dir', BASE_DIR / 'exports')
            export_dir.mkdir(parents=True, exist_ok=True)
            
            csv_file = export_dir / f"properties_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            db.export_to_csv(csv_file, rank_filter=['S', 'A', 'B'])
            logger.info(f"\nCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›ã—ã¾ã—ãŸ: {csv_file}")
        
        logger.info("\n" + "="*60)
        logger.info("ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ­£å¸¸çµ‚äº†")
        logger.info("="*60)
        
    except Exception as e:
        logger.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
        sys.exit(1)


def show_status():
    """ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¡¨ç¤º"""
    logger = setup_logging()
    
    try:
        db = PropertyDatabase(DATABASE_CONFIG['db_path'])
        stats = db.get_statistics()
        
        print("\n" + "="*60)
        print("ğŸ“Š Athome Property Scraper ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹")
        print("="*60)
        
        # ç·ç‰©ä»¶æ•°
        print(f"ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ç‰©ä»¶æ•°: {stats.get('total_active_properties', 0)}ä»¶")
        
        # ãƒ©ãƒ³ã‚¯åˆ¥
        if stats.get('properties_by_rank'):
            print("\nã€ãƒ©ãƒ³ã‚¯åˆ¥ç‰©ä»¶æ•°ã€‘")
            for rank in ['S', 'A', 'B', 'C', 'D']:
                count = stats['properties_by_rank'].get(rank, 0)
                bar = 'â–ˆ' * (count // 2) if count > 0 else ''
                print(f"  {rank}ç´š: {count:3d}ä»¶ {bar}")
        
        # æœ€çµ‚å®Ÿè¡Œ
        if stats.get('last_scraping'):
            print(f"\nã€æœ€çµ‚ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã€‘")
            print(f"  å®Ÿè¡Œæ™‚åˆ»: {stats['last_scraping']['time']}")
            print(f"  æ–°è¦ç‰©ä»¶: {stats['last_scraping']['new_properties']}ä»¶")
            print(f"  ç·ä»¶æ•°: {stats['last_scraping']['total_properties']}ä»¶")
        
        # é«˜ãƒ©ãƒ³ã‚¯ç‰©ä»¶
        if stats.get('high_rank_properties'):
            print("\nã€é«˜ãƒ©ãƒ³ã‚¯ç‰©ä»¶ TOP5ã€‘")
            for i, prop in enumerate(stats['high_rank_properties'][:5], 1):
                print(f"  {i}. {prop['ranking_grade']}ç´š ({prop['ranking_score']:.1f}ç‚¹)")
                print(f"     {prop['title'][:30]}...")
                print(f"     {prop['price']} - {prop['address'][:20]}")
                print()
        
        print("="*60)
        
    except Exception as e:
        logger.error(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


def show_help():
    """ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º"""
    print("""
Athome Property Scraper - å¤§åˆ†å¸‚å£²åœŸåœ°æƒ…å ±è‡ªå‹•åé›†ã‚·ã‚¹ãƒ†ãƒ 

ä½¿ç”¨æ–¹æ³•:
    python run_scraper.py [ã‚³ãƒãƒ³ãƒ‰]

ã‚³ãƒãƒ³ãƒ‰:
    run      - ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’å®Ÿè¡Œï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
    status   - ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¡¨ç¤º
    help     - ã“ã®ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º

ä¾‹:
    python run_scraper.py            # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ
    python run_scraper.py status     # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
    python run_scraper.py help       # ãƒ˜ãƒ«ãƒ—è¡¨ç¤º

è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«:
    config/athome_scraper_config.py ã§å„ç¨®è¨­å®šã‚’å¤‰æ›´ã§ãã¾ã™
    
ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«:
    logs/scraper_YYYYMMDD.log ã«å®Ÿè¡Œãƒ­ã‚°ãŒä¿å­˜ã•ã‚Œã¾ã™
    """)


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’å‡¦ç†
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        
        if command == 'status':
            show_status()
        elif command == 'help' or command == '-h' or command == '--help':
            show_help()
        elif command == 'run':
            run_scraping()
        else:
            print(f"ä¸æ˜ãªã‚³ãƒãƒ³ãƒ‰: {command}")
            print("ä½¿ç”¨æ–¹æ³•: python run_scraper.py [run|status|help]")
            sys.exit(1)
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ
        run_scraping()


if __name__ == "__main__":
    main()